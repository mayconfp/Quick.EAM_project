from .llama_cliente import gerar_resposta_llama
from .gemini_cliente import gemini_gerar_resposta
import logging
from .models import ChatHistory
from .openai_cliente import processar_arquivo
from .openai_cliente import carregar_conhecimento
from .openai_cliente import buscar_no_json
from .openai_cliente import buscar_no_json, carregar_conhecimento, gerar_resposta_openai, processar_arquivo
import os
import fitz

logger = logging.getLogger(__name__)


def gerar_resposta(user_message, chat_history=None, file_path=None, contexto_adicional=None):
    """Gera uma resposta consolidada com base no JSON, arquivos e IA."""

    if not isinstance(user_message, str) or not user_message.strip():
        logger.warning("Mensagem invÃ¡lida recebida.")
        return "NÃ£o entendi sua mensagem. Pode reformular?"

    user_message = user_message.strip()

    # ðŸ”Ž **Busca no JSON primeiro**
    resposta_json = buscar_no_json(user_message, carregar_conhecimento())
    if resposta_json:
        return resposta_json  

    # ðŸ”¥ **Processa o arquivo se houver e extrai o texto**
    extracted_text = None
    if file_path:
        extracted_text = processar_arquivo(file_path)

    # ðŸ”¥ **Se o PDF contÃ©m informaÃ§Ãµes, adiciona ao contexto da IA**
    if extracted_text:
        contexto_adicional = (contexto_adicional or "") + f"\n\n[ConteÃºdo do PDF]:\n{extracted_text}"

    # ðŸ”Ž **Se nÃ£o encontrou no JSON, chama a OpenAI**
    return gerar_resposta_openai(user_message, chat_history, contexto_adicional)




def processar_comunicacao_multi_ia(user_message, historico):
    """Processa a mensagem consultando JSON antes de usar IAs externas."""

    if not user_message.strip():
        return "A mensagem nÃ£o pode estar vazia."

    # ðŸ”Ž **Verifica se Ã© um pedido de resumo**
    if "resuma" in user_message.lower() or "resumo" in user_message.lower():
        return gerar_resposta(user_message, [])  # Remove contexto da QuickEAM

    respostas = {}

    try:
        respostas['openai'] = gerar_resposta(user_message, historico)
    except Exception as e:
        print(f"[ERROR] Erro na OpenAI: {e}")
        respostas['openai'] = None

    melhor_resposta = respostas.get('openai')

    return melhor_resposta or "Desculpe, nÃ£o consegui gerar uma resposta no momento."




def recuperar_ultima_resposta(user):
    """
    Recupera a Ãºltima resposta registrada no banco de dados para o usuÃ¡rio.
    """
    try:
        ultima_resposta = ChatHistory.objects.filter(session__user=user).order_by('-timestamp').first()
        if ultima_resposta and ultima_resposta.answer.strip():
            print(f"[DEBUG] Ãšltima resposta encontrada: {ultima_resposta.answer}")
            return ultima_resposta.answer.strip()
        else:
            print("[DEBUG] Nenhuma resposta anterior vÃ¡lida encontrada.")
            return None
    except Exception as e:
        print(f"[ERROR] Erro ao recuperar Ãºltima resposta: {e}")
        return None
